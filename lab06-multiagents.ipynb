{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-agent systems with Autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tiktoken==0.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.conditions import MaxMessageTermination, TextMentionTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import BingGroundingTool,CodeInterpreterTool\n",
    "import os\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orchestrate a single agent with Autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import BingGroundingTool\n",
    "\n",
    "token_provider = get_bearer_token_provider(\n",
    "    DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\"\n",
    ")\n",
    "\n",
    "az_model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_deployment=\"gpt-4-turbo\",\n",
    "    model = \"gpt-4-turbo\",\n",
    "    api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    azure_endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    azure_ad_token_provider=token_provider,\n",
    ")\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    conn_str=os.environ.get(\"PROJECT_CONNECTION_STRING\"),\n",
    ")\n",
    "bing_connection = project_client.connections.get(\n",
    "    connection_name=os.environ.get(\"BING_CONNECTION_NAME\")\n",
    ")\n",
    "\n",
    "conn_id = bing_connection.id\n",
    "async def web_ai_agent(query: str) -> str:\n",
    "    print(\"This is Bing for Azure AI Agent Service .......\")\n",
    "    bing = BingGroundingTool(connection_id=conn_id)\n",
    "    with project_client:\n",
    "        agent = project_client.agents.create_agent(\n",
    "            model=\"gpt-4-turbo\",\n",
    "            name=\"my-assistant\",\n",
    "            instructions=\"\"\"        \n",
    "                You are a web search agent.\n",
    "                Your only tool is search_tool - use it to find information.\n",
    "                You make only one search call at a time.\n",
    "                Once you have the results, you never do calculations based on them.\n",
    "            \"\"\",\n",
    "            tools=bing.definitions,\n",
    "            headers={\"x-ms-enable-preview\": \"true\"}\n",
    "        )\n",
    "        print(f\"Created agent, ID: {agent.id}\")\n",
    "\n",
    "        # Create thread for communication\n",
    "        thread = project_client.agents.create_thread()\n",
    "        print(f\"Created thread, ID: {thread.id}\")\n",
    "\n",
    "        # Create message to thread\n",
    "        message = project_client.agents.create_message(\n",
    "            thread_id=thread.id,\n",
    "            role=\"user\",\n",
    "            content=query,\n",
    "        )\n",
    "        print(f\"User Message: {message}\")\n",
    "        # Create and process agent run in thread with tools\n",
    "        run = project_client.agents.create_and_process_run(thread_id=thread.id, assistant_id=agent.id)\n",
    "        print(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "        if run.status == \"failed\":\n",
    "            print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "        # Delete the assistant when done\n",
    "        project_client.agents.delete_agent(agent.id)\n",
    "        print(\"Deleted agent\")\n",
    "\n",
    "        # Fetch and log all messages\n",
    "        messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "        print(\"Messages:\"+ messages[\"data\"][0][\"content\"][0][\"text\"][\"value\"])\n",
    "    return messages[\"data\"][0][\"content\"][0][\"text\"][\"value\"]\n",
    "bing_search_agent = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=az_model_client,\n",
    "    tools=[web_ai_agent],\n",
    "    system_message=\"Use tools to solve tasks.\",\n",
    ")\n",
    "bing = BingGroundingTool(connection_id=conn_id)\n",
    "async def assistant_run() -> None:\n",
    "    response = await bing_search_agent.on_messages(\n",
    "            [TextMessage(content=\"What is GitHub Copilot?\", source=\"user\")],\n",
    "            cancellation_token=CancellationToken(),\n",
    "    )\n",
    "#     print(response.inner_messages)\n",
    "    print(response.chat_message)\n",
    "await assistant_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orchestrate several agents with Autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_provider = get_bearer_token_provider(\n",
    "    DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\"\n",
    ")\n",
    "\n",
    "az_model_client  = AzureOpenAIChatCompletionClient(\n",
    "    azure_deployment=\"gpt-4-turbo\",\n",
    "    model = \"gpt-4-turbo\",\n",
    "    api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    azure_endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    azure_ad_token_provider=token_provider,\n",
    ")\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    conn_str=os.environ.get(\"PROJECT_CONNECTION_STRING\"),\n",
    ")\n",
    "bing_connection = project_client.connections.get(\n",
    "    connection_name=os.environ.get(\"BING_CONNECTION_NAME\")\n",
    ")\n",
    "\n",
    "conn_id = bing_connection.id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def web_ai_agent(query: str) -> str:\n",
    "    print(\"This is Bing for Azure AI Agent Service .......\")\n",
    "    bing = BingGroundingTool(connection_id=conn_id)\n",
    "    # with project_client:\n",
    "    agent = project_client.agents.create_agent(\n",
    "            model=\"gpt-4-turbo\",\n",
    "            name=\"my-assistant\",\n",
    "            instructions=\"\"\"        \n",
    "                You are a web search agent.\n",
    "                Your only tool is search_tool - use it to find information.\n",
    "                You make only one search call at a time.\n",
    "                Once you have the results, you never do calculations based on them.\n",
    "            \"\"\",\n",
    "            tools=bing.definitions,\n",
    "            headers={\"x-ms-enable-preview\": \"true\"}\n",
    "        )\n",
    "    print(f\"Created agent, ID: {agent.id}\")\n",
    "\n",
    "    # Create thread for communication\n",
    "    thread = project_client.agents.create_thread()\n",
    "    print(f\"Created thread, ID: {thread.id}\")\n",
    "\n",
    "    # Create message to thread\n",
    "    message = project_client.agents.create_message(\n",
    "            thread_id=thread.id,\n",
    "            role=\"user\",\n",
    "            content=query,\n",
    "    )\n",
    "    print(f\"SMS: {message}\")\n",
    "        # Create and process agent run in thread with tools\n",
    "    run = project_client.agents.create_and_process_run(thread_id=thread.id, assistant_id=agent.id)\n",
    "    print(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "    if run.status == \"failed\":\n",
    "        print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "        # Delete the assistant when done\n",
    "    project_client.agents.delete_agent(agent.id)\n",
    "    print(\"Deleted agent\")\n",
    "\n",
    "        # Fetch and log all messages\n",
    "    messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "    print(\"Messages:\"+ messages[\"data\"][0][\"content\"][0][\"text\"][\"value\"])\n",
    "\n",
    "        # project_client.close()\n",
    "\n",
    "    return messages[\"data\"][0][\"content\"][0][\"text\"][\"value\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def save_blog_agent(blog_content: str) -> str:\n",
    "\n",
    "    print(\"This is Code Interpreter for Azure AI Agent Service .......\")\n",
    "\n",
    "\n",
    "    code_interpreter = CodeInterpreterTool()\n",
    "        \n",
    "    agent = project_client.agents.create_agent(\n",
    "            model=\"gpt-4-turbo\",\n",
    "            name=\"my-agent\",\n",
    "            instructions=\"You are helpful agent\",\n",
    "            tools=code_interpreter.definitions,\n",
    "            # tool_resources=code_interpreter.resources,\n",
    "    )\n",
    "\n",
    "    thread = project_client.agents.create_thread()\n",
    "\n",
    "    message = project_client.agents.create_message(\n",
    "            thread_id=thread.id,\n",
    "            role=\"user\",\n",
    "            content=\"\"\"\n",
    "        \n",
    "                    You are my Python programming assistant. Generate code,save \"\"\"+ blog_content +\n",
    "                    \n",
    "                \"\"\"    \n",
    "                    and execute it according to the following requirements\n",
    "\n",
    "                    1. Save blog content to blog-{YYMMDDHHMMSS}.md\n",
    "\n",
    "                    2. give me the download this file link\n",
    "                \"\"\",\n",
    "    )\n",
    "    # create and execute a run\n",
    "    run = project_client.agents.create_and_process_run(thread_id=thread.id, assistant_id=agent.id)\n",
    "    print(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "    if run.status == \"failed\":\n",
    "            # Check if you got \"Rate limit is exceeded.\", then you want to get more quota\n",
    "        print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "        # # delete the original file from the agent to free up space (note: this does not delete your version of the file)\n",
    "        # project_client.agents.delete_file(file.id)\n",
    "        # print(\"Deleted file\")\n",
    "\n",
    "        # print the messages from the agent\n",
    "    messages = project_client.agents.get_messages(thread_id=thread.id)\n",
    "    print(f\"Messages: {messages}\")\n",
    "\n",
    "        # get the most recent message from the assistant\n",
    "    last_msg = messages.get_last_text_message_by_sender(\"assistant\")\n",
    "    if last_msg:\n",
    "        print(f\"Last Message: {last_msg.text.value}\")\n",
    "\n",
    "        # print(f\"File: {messages.file_path_annotations}\")\n",
    "\n",
    "\n",
    "    for file_path_annotation in messages.file_path_annotations:\n",
    "\n",
    "        file_name = os.path.basename(file_path_annotation.text)\n",
    "\n",
    "        project_client.agents.save_file(file_id=file_path_annotation.file_path.file_id, file_name=file_name,target_dir=\"./blog\")\n",
    "        \n",
    "\n",
    "    project_client.agents.delete_agent(agent.id)\n",
    "    print(\"Deleted agent\")\n",
    "\n",
    "\n",
    "        # project_client.close()\n",
    "\n",
    "\n",
    "    return \"Saved\"\n",
    "\n",
    "\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "bing_search_agent = AssistantAgent(\n",
    "    name=\"bing_search_agent\",\n",
    "    model_client=az_model_client,\n",
    "    tools=[web_ai_agent],\n",
    "    system_message=\"You are a search expert, help me use tools to find relevant knowledge\",\n",
    ")\n",
    "save_blog_content_agent = AssistantAgent(\n",
    "    name=\"save_blog_content_agent\",\n",
    "    model_client=az_model_client,\n",
    "    tools=[save_blog_agent],\n",
    "    system_message=\"\"\"\n",
    "        Save blog content. Respond with 'Saved' to when your blog are saved.\n",
    "    \"\"\"\n",
    ")\n",
    "write_agent = AssistantAgent(\n",
    "    name=\"write_agent\",\n",
    "    model_client=az_model_client,\n",
    "    system_message=\"\"\"\n",
    "        You are a blog writer, please help me write a blog based on bing search content.\"\n",
    "    \"\"\"\n",
    ")\n",
    "text_termination = TextMentionTermination(\"Saved\")\n",
    "# Define a termination condition that stops the task after 5 messages.\n",
    "max_message_termination = MaxMessageTermination(10)\n",
    "# Combine the termination conditions using the `|`` operator so that the\n",
    "# task stops when either condition is met.\n",
    "termination = text_termination | max_message_termination\n",
    "reflection_team = RoundRobinGroupChat([bing_search_agent, write_agent,save_blog_content_agent], termination_condition=termination)\n",
    "await Console(\n",
    "    reflection_team.run_stream(task=\"\"\"\n",
    "\n",
    "                    I am writing a blog about machine learning. Search for the following 3 questions and write a blog based on the search results ,save it\n",
    "                    \n",
    "                    1. What is Machine Learning?\n",
    "                    2. The difference between AI and ML\n",
    "                    3. The history of Machine Learning\n",
    "                               \n",
    "\n",
    "    \"\"\")\n",
    ")  # Stream the messages to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
